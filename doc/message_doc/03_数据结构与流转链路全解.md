# 消息发送全链路数据结构与转化流程

本说明记录了一条消息从客户端发出，经过网关、消息服务处理、持久化、事件分发，最终通过 Connect 服务投递到接收方客户端的生命周期。整个过程涉及多个关键数据结构在不同环节间的转化。

---

## 链路核心节点与结构流转概览

```
[1. 客户端]
    ↓ (HTTP JSON - 发送请求DTO)
[2. Gateway (API网关)] 
    ↓ (gRPC Proto - SendMessageRequest)
[3. Msg-Service (逻辑与持久化)]
    ↓ (GORM Model - Message & Conversation 落库)
    ↓ (Protobuf - MsgPushEvent 写入Kafka，立即返回200)
[4. Kafka Message Queue]
    ↓ (Protobuf - MsgPushEvent 消费)
[5. Push-Job (Kafka消费者调度器)]
    ↓ (查 Redis 路由表 user:routing:{uuid}，确定 Connect 节点 IP)
    ↓ (gRPC PushToUser / PushToDevice 调用)
[6. Connect-Service (纯管道投递)]
    ↓ (Protobuf - MessageEnvelope -> WebSocket Binary)
[7. 接收端] (WebSocket Binary - 最终业务展示)
```

---

## 1. 结构详情与流转阶段

### 阶段一：客户端 -> Gateway

#### `SendMessageRequest` (DTO / HTTP JSON)

这是客户端调用发送消息 API 时传递的参数结构。Gateway 收到后进行鉴权和参数校验。

**结构定义**（参考 DTO）：
```json
{
  "client_msg_id": "c3f8a1b2-...", // [必填] 客户端幂等ID(UUID)，用于处理弱网重发去重
  "conv_type": 1,                   // [必填] 会话类型：1=单聊，2=群聊
  "target_uuid": "usr_abcdef...",   // [必填] 目标端（单聊=接收方UUID，群聊=群UUID）
  "msg_type": 1,                    // [必填] 消息类型代号（如：1=文本, 2=图片）
  "content": "{\"text\":\"你好\"}",   // [必填] 消息的业务负载，必须是序列化后的JSON字符串
  "reply_to_msg_id": "",            // [可选] 引用的目标消息全局ID
  "at_users": []                    // [可选] 艾特人员UUID列表，@全员用特殊UUID
}
```
**转化动作**：Gateway 在鉴权中间件中解析拦截提取用户的 `uuid` (作为 `from_uuid`) 和 `device_id`。

---

### 阶段二：Gateway -> Msg-Service

#### `SendMessageRequest` (gRPC Proto)

Gateway 将 HTTP 层收到的 DTO 组包转为 gRPC 请求。这里补齐了发送方的关键身份信息。

**结构定义** (`proto/msg/msg_service.proto`)：
```protobuf
message SendMessageRequest {
  string from_uuid = 1;       // 由 Gateway 注入，发送者UUID
  string device_id = 2;       // 由 Gateway 注入，发送设备ID
  ConvType conv_type = 3;     // DTO原样传入
  string target_uuid = 4;     // DTO原样传入
  string client_msg_id = 5;   // DTO原样传入
  int32 msg_type = 6;         // DTO原样传入
  string content = 7;         // DTO原样传入
  string reply_to_msg_id = 8; // DTO原样传入
  repeated string at_users = 9; // DTO原样传入
}
```
**内部作用**：到达 Msg-Service 后，`(from_uuid, device_id, client_msg_id)` 三元组可确定唯一请求，用作全局防重（Redis判定）。

---

### 阶段三：Msg-Service (内部处理 & 持久化)

消息处理阶段，Msg-Service 通过雪花算法或 ULID 分配 `msg_id`，利用 Redis Incr 获取会话严格递增序列号 `seq`，拼装数据库模型后落库。主要涉及两张核心表：

#### `Message` 模型 (数据库，保存消息实体)
**结构定义** (`model/Message.go`)：
```go
type Message struct {
  Id           int64   // 主键
  ConvId       string  // 动态计算，单聊=按字母序拼接(p2p-A-B)，群聊=群UUID
  Seq          int64   // [核心] Redis返回的唯一递增序列号，客户端据此判断断层(Gap)并拉取
  MsgId        string  // 新生成，全局唯一消息ID (下发给前端作为引用ID等)
  ClientMsgId  string  // 来自 gRPC Proto
  FromUuid     string  // 来自 gRPC Proto
  DeviceId     string  // 来自 gRPC Proto (用于三元组防重)
  MsgType      int16   // 来自 gRPC Proto
  Content      string  // 来自 gRPC Proto
  Status       int8    // 初始化为 0的(正常)
  ReplyToMsgId string  // 来自 gRPC Proto
  AtUsers      string  // 来自 gRPC Proto (转 JSON 存入DB)
  SendTime     time.Time // 服务端时间，也就是接收该请求时的时间戳
}
```

#### `Conversation` 模型 (数据库，更新会话状态)

**结构定义** (`model/Conversation.go`)：
```go
type Conversation struct {
  // ... 其他基础字段 ...
  MaxSeq      int64 // [核心] 刷新成刚才取出的 Message Seq
  ReadSeq     int64 // 不变
  UnreadCount int   // 当对象是接收方时，通过公式计算 max(0, max_seq - read_seq) 动态更新
  LastMsgId   string// 变更为 Message 的 MsgId
  LastMsgAt   time.Time // 等于 Message 的 SendTime
  // ... 其他基础字段 ...
}
```

**转化动作（按 conv_type 分治）**：

| | 单聊（conv_type=1，写扩散） | 群聊（conv_type=2，读扩散） |
|--|--|--|
| **Message 落库** | 1 条 | 1 条 |
| **发送方 Conversation** | Upsert，更新 MaxSeq/LastMsg | Upsert，更新 MaxSeq/LastMsg |
| **接收方 Conversation** | Upsert，更新 MaxSeq/LastMsg | ❌ **不更新！** 只更新群级 MaxSeq |
| **未读数** | max(0, max_seq - read_seq) | 拉取会话时动态计算 |

> **❗ 群聊落库核心约束**：  
> **绝对不能**在发消息时 Upsert 所有群成员的 Conversation 记录！  
> 2000 人群发 1 条消息 = 2000 次 DB 写入，这就是“写放大”，严重违背了读扩散设计的初衷。  
> 正确做法：只更新**群级**会话的 `MaxSeq`，成员的未读数在其拉取会话列表时通过 `max(0, group.max_seq - member.read_seq)` 动态计算。

---

### 阶段四：Msg-Service -> Kafka

消息落库后，向外分发。Msg-Service 不直接调用任何下游服务，而是丢入一条 Kafka 任务后**立即返回**，Kafka 是上行发送与下行推送之间的“防弹衣”。

**Kafka 分区策略**：
- **Partition Key**：`conv_id`（不是 receiver_uuid）
- **原因**：同一会话的连续消息必须落入同一个 Partition，确保 Push-Job 串行消费时严格有序
- **反例**：若用 receiver_uuid，A 给 B 连发两条消息可能分到不同 Partition，B 先收到第二条后收到第一条，产生视觉闪烁

#### `MsgPushEvent` (Kafka Value，Proto序列化 bytes)
根据前置判断生成的推送决策：如果是单聊，就投递到对方 UUID (写扩散)；如果是群聊，就把包的接收对象指向群 UUID (读扩散)。

**结构定义** (`proto/msg/msg_push_event.proto`)：
```protobuf
message MsgPushEvent {
  string receiver_uuid = 1; // 接收对象的ID (对方UUID 或 群UUID)
  string device_id = 2;     // 发送方当前设备 ID（Self-Sync 时排除该设备）
  string type = 3;          // "MSG_PUSH"表示这属于一条新消息内容
  ConvType conv_type = 4;   // Push-Job 据此决定扩散策略（1=单聊写扩散 2=群聊读扩散）
  bytes data = 5;           // MsgItem proto 的二进制（新消息实体）
  string trace_id = 6;      
  int64 server_ts = 7;
  string from_uuid = 8;     // 发送方 UUID（用于多端同步 Self-Sync）
}
```

**转化动作**：msg-service 根据上下文填充字段后，序列化写入 Kafka：
- `receiver_uuid`：单聊填对端 UUID，群聊填群 UUID
- `from_uuid`：始终填发送方 UUID（从 gRPC 的 `SendMessageRequest.from_uuid` 透传）
- `device_id`：填发送方当前设备 ID（Push-Job 据此在 Self-Sync 时排除该设备）
- `data`：将落库后的 `Message` 模型字段转化为 `MsgItem` proto 并序列化为 bytes

---

### 阶段五：Kafka -> Push-Job -> Redis 路由 -> Connect gRPC -> Client

**Push-Job**（独立 Kafka 消费者服务）消费 Kafka，解码出 `MsgPushEvent`。Push-Job 是整条下行链路中唯一需要“动脑子”的节点，负责扩散策略、路由查询和 Self-Sync。Connect 只是纯管道。

Push-Job 的处理分三步：

**① 确定目标用户列表**（按 conv_type 分支）：
- 单聊(conv_type=1)：targets = [receiver_uuid]
- 群聊(conv_type=2)：查询 Redis 群成员列表，过滤 `from_uuid`

**② 查 Redis 路由表，精确找到 Connect 节点**：
- 对每个 target_uuid，执行 `HGETALL user:routing:{target_uuid}`
- 得到 `{ device_id: connect_grpc_addr }` 映射
- 按 grpc_addr 分组，通过 gRPC 调用 `ConnectService.PushToUser(target_uuid, envelope)`

**③ 发送方多端同步（Self-Sync）**：
- 查询 `HGETALL user:routing:{from_uuid}`，过滤掉 `device_id`
- 对剩余设备所在的 Connect 节点调用 `PushToDevice(from_uuid, other_device, envelope)`
- 客户端通过 `MsgItem.from_uuid == 自己的UUID` 判断这是多端同步而不是对方发的消息

最终 Connect 收到 gRPC 调用后，通过 WebSocket 下发二进制，协议为 **MessageEnvelope**。

#### `MessageEnvelope` (WebSocket Binary 下行通信)

**结构定义** (`proto/connect/connect.proto`)：
```protobuf
message MessageEnvelope {
  string type = 1;       // == MsgPushEvent.type ("MSG_PUSH")
  bytes data = 2;        // == MsgPushEvent.data (也是一层协议，本场景为MsgItem)
  int64 seq = 3;         // WebSocket自身流的保证序号
  int64 server_ts = 4;   // 事件发生时间戳
  string trace_id = 5;
  bool ack_required = 6; // 决定前端是不是要回复确认接收
}
```

#### `MsgItem` (客户端真正解析的业务消息结构)
前端收到 WebSocket 并剥开 Envelope 发现是 `MSG_PUSH` 后，再把内部 `data` 解码出最终消息数据 `MsgItem`，此时完成漫长的旅游，供UI绘制。

**结构定义** (`proto/msg/msg_common.proto`)：
```protobuf
message MsgItem {
  string msg_id = 1;          // -> 渲染给长按功能使用
  string client_msg_id = 2;   // -> 发送者本人依据此找到本地假消息，换为真发送标记
  string conv_id = 3;         // -> 归属聊天列表
  int64 seq = 4;              // -> 判断消息列表是否出现不连续序号
  string from_uuid = 5;       // -> 显示发言人头像网名
  int32 msg_type = 6;         // 
  string content = 7;         // -> 转为 JSON后拿出去画气泡
  int32 status = 8;
  int64 send_time = 9;
  string reply_to_msg_id = 10;
  repeated string at_users = 11;
}
```

---

### 返回阶段：Msg-Service -> Gateway -> 发送端 Client

前面的 阶段三 和 阶段四/五 实际上是**同步进行/分离**的：Msg-Service 在将消息写完数据库，并且 `Produce` 推送进入 Kafka 之后（甚至可配置无需等待投递Ack），主协程的 RPC 请求就会结束了。返回给调用的源头 Gateway 并封装回传到正在等待发消息网络响应结果的前端。

#### `SendMessageResponse` (HTTP 成功回应体)
**结构定义** (最终到达前端 DTO)：
```json
{
  "code": 0,
  "message": "success",
  "data": {
    "msg_id": "01HW5K...",    // 新产生的服务端的 UUID，作为以后所有对该对象引用/撤回的凭证
    "seq": 42,                // 生成的准确自增位置序号
    "conv_id": "p2p-AAA-BBB", // 这个会话正确的拼接表示法，用于日后拉取参数
    "send_time": 1740391200000 // 录入系统的时间
  },
  "trace_id": "...",
  "timestamp": 1740391200000
}
```
此时客户端收到这条响应，就表明刚才上行的消息**已确定安稳到达服务器**，本地由灰色加载状态切换为完成，不必强行依赖必须等待长连接发回 WebSocket 数据流广播证明。
